{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wide ResNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oe2t-NA4jby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://github.com/OlafenwaMoses/IdenProf/releases/download/v1.0/idenprof-jpg.zip\n",
        "# !unzip idenprof-jpg.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZqOhXXSwNOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M9SQ9cY4Z5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms_train = transforms.Compose([transforms.Resize(225),\n",
        "                                       transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                                                            [0.5, 0.5, 0.5])])\n",
        "\n",
        "transforms_test = transforms.Compose([transforms.Resize(225),\n",
        "                                       transforms.CenterCrop(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                                                            [0.5, 0.5, 0.5])])\n",
        "\n",
        "batch_sizes = 32\n",
        "test_data_dir = './idenprof/test'\n",
        "train_data_dir = './idenprof/test'\n",
        "\n",
        "train_data = datasets.ImageFolder(root=train_data_dir, transform=transforms_train)\n",
        "test_data = datasets.ImageFolder(root=test_data_dir, transform=transforms_test)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_sizes, shuffle=True)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_sizes, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1NJYRbH54An",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = next(iter(train_data_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5WXxHIU6WIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_display(image, title=None):\n",
        "    image = image/2 + 0.5\n",
        "    numpy_image = image.numpy()\n",
        "    transposed_numpy_image = np.transpose(numpy_image, (1, 2, 0))\n",
        "    plt.figure(figsize=(60, 8))\n",
        "    plt.imshow(transposed_numpy_image)\n",
        "    plt.yticks([])\n",
        "    plt.xticks([])\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Yru3736fB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_display(torchvision.utils.make_grid(images), [train_data.classes[x] for x in labels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ8AenaQF758",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Batch_Norm_Relu_Conv2d(nn.Module):\n",
        "    \n",
        "    def __init__(self, number_in_channels, number_out_channels, kernel_size, stride, padding):\n",
        "        \n",
        "        super(Batch_Norm_Relu_Conv2d, self).__init__()\n",
        "        \n",
        "        self.batch_normalization = nn.BatchNorm2d(number_in_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.conv2d = nn.Conv2d(number_in_channels, number_out_channels, kernel_size=kernel_size, \n",
        "                                stride=stride, padding=padding, bias=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_normalized_input = self.batch_normalization(x)\n",
        "        \n",
        "        relu_activated_input = self.relu(batch_normalized_input)\n",
        "        \n",
        "        return self.conv2d(relu_activated_input)\n",
        " \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSGm3X1p81fS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Residual_Unit(nn.Module):\n",
        "    \n",
        "    def __init__(self, number_in_channels, number_out_channels, kernel_size, stride, padding, drop_out_value):\n",
        "        \n",
        "        super(Residual_Unit, self).__init__()\n",
        "        \n",
        "        self.batch_norm_relu1 = Batch_Norm_Relu_Conv2d(number_in_channels, \n",
        "                                             number_out_channels, kernel_size, stride, padding)\n",
        "        \n",
        "        self.batch_norm_relu2 = Batch_Norm_Relu_Conv2d(number_out_channels, \n",
        "                                             number_out_channels, kernel_size, 1, padding)\n",
        "        \n",
        "        self.dropout = nn.Dropout2d(p=drop_out_value)\n",
        "        \n",
        "        self.identity_function = nn.Sequential(nn.Conv2d(number_in_channels, number_out_channels, 1, stride, \n",
        "                                               0)) if stride == 2 or number_in_channels != number_out_channels else nn.Sequential()\n",
        "        \n",
        "        self.dropout = nn.Dropout2d(p=drop_out_value)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x_input = self.identity_function(x)\n",
        "        \n",
        "        y_input = x\n",
        "        \n",
        "        y_input = self.dropout(self.batch_norm_relu1(y_input))\n",
        "        \n",
        "        y_input = self.batch_norm_relu2(y_input)\n",
        "        \n",
        "        y_output = x_input + y_input\n",
        "        \n",
        "        return y_output\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27qGGGvKMLtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Residual_Block(nn.Module):\n",
        "    \n",
        "    def __init__(self, number_in_channels, number_out_channels, kernel_size, \n",
        "                                stride, padding, drop_out_value, number_of_residual_units):\n",
        "        \n",
        "        super(Residual_Block, self).__init__()\n",
        "        \n",
        "        residual_units = []\n",
        "        \n",
        "        residual_units.append(Residual_Unit(number_in_channels, number_out_channels, kernel_size, \n",
        "                                                            stride, padding, drop_out_value))\n",
        "        \n",
        "        for i in range(number_of_residual_units - 1):\n",
        "            \n",
        "            residual_units.append(Residual_Unit(number_out_channels, number_out_channels, kernel_size, \n",
        "                                                            1, padding, drop_out_value))\n",
        "            \n",
        "        self.residual_block = nn.Sequential(*residual_units)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        residual_block_input = x\n",
        "        \n",
        "        residual_block_output = self.residual_block(residual_block_input)\n",
        "        \n",
        "        return residual_block_output\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTdyXzdIkTtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WideResNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, depth, drop_out_value, num_classes=10, widing_factor_k=1):\n",
        "        \n",
        "        super(WideResNet, self).__init__()\n",
        "        \n",
        "        n = (depth-4)/6\n",
        "        \n",
        "        number_of_residual_units = int(n)\n",
        "        \n",
        "        self.first_conv_layer = nn.Conv2d(3, 16, 3, 2, 1)\n",
        "        \n",
        "        self.residual_block1 = Residual_Block(16, 16*widing_factor_k, 3, 2, 1, drop_out_value, number_of_residual_units)\n",
        "        \n",
        "        self.residual_block2 = Residual_Block(16*widing_factor_k,32*widing_factor_k, 3, 2, 1, drop_out_value, number_of_residual_units)\n",
        "        \n",
        "        self.residual_block3 = Residual_Block(32*widing_factor_k, 64*widing_factor_k, 3, 2, 1, drop_out_value, number_of_residual_units)\n",
        "        \n",
        "        self.batch_normalization = nn.BatchNorm2d(64*widing_factor_k)\n",
        "        \n",
        "        self.global_average_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        \n",
        "        self.classifier = nn.Linear(64*widing_factor_k, num_classes)\n",
        "        \n",
        "        for m in self.modules():\n",
        "            \n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                \n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            \n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                \n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                \n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "       \n",
        "    def forward(self, x):\n",
        "        \n",
        "        y = F.relu(self.first_conv_layer(x))\n",
        "        \n",
        "        y = self.residual_block1(y)\n",
        "        \n",
        "        y = self.residual_block2(y)\n",
        "        \n",
        "        y = F.relu(self.batch_normalization(self.residual_block3(y)))\n",
        "        \n",
        "        y = self.global_average_pool(y)\n",
        "        \n",
        "        y = y.view(y.size(0),-1)\n",
        "        \n",
        "        output_logit = self.classifier(y)\n",
        "\n",
        "        return output_logit\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSHa9xVyKX3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Model = WideResNet(40, 0.25, widing_factor_k=4) \n",
        "\n",
        "lr = 0.01\n",
        "\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(Model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "milestones = [70, 100, 150]\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkSO8pyGM1Fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgFzObeBOUkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_traing_and_validation_loop(Model, n_epochs, save_path):\n",
        "    \n",
        "    n_epochs = n_epochs\n",
        "\n",
        "    saving_criteria_of_model = 0\n",
        "\n",
        "    training_loss_array = []\n",
        "\n",
        "    validation_loss_array = []\n",
        "\n",
        "    Model = Model.to(device)\n",
        "\n",
        "    for i in range(n_epochs):\n",
        "\n",
        "        total_test_data = 0\n",
        "\n",
        "        total_train_data = 0\n",
        "\n",
        "        correct_test_data = 0\n",
        "\n",
        "        training_loss = 0\n",
        "\n",
        "        validation_loss = 0\n",
        "\n",
        "        for data, target in train_data_loader:\n",
        "\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logit = Model(data)\n",
        "\n",
        "            loss = criteria(logit, target)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            training_loss += loss.item()*data.size(0)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for data, target in test_data_loader:\n",
        "\n",
        "                data, target = data.to(device), target.to(device)\n",
        "\n",
        "                logit = Model(data)\n",
        "\n",
        "                _, prediction = torch.max(logit, 1) \n",
        "\n",
        "                loss = criteria(logit, target)\n",
        "\n",
        "                total_test_data += target.size(0)\n",
        "\n",
        "                correct_test_data += (prediction == target).sum().item()\n",
        "\n",
        "                validation_loss += loss.item()*data.size(0)\n",
        "                \n",
        "        training_loss = training_loss / len(train_data)\n",
        "        \n",
        "        validation_loss = validation_loss / total_test_data\n",
        "\n",
        "        training_loss_array.append(training_loss)\n",
        "\n",
        "        validation_loss_array.append(validation_loss)\n",
        "\n",
        "        validation_accuracy = correct_test_data / total_test_data\n",
        "\n",
        "        print(f'{i+1} / {n_epochs} Training loss: {training_loss}, Validation_loss: {validation_loss}, Validation_Accuracy: {validation_accuracy}')\n",
        "\n",
        "        if saving_criteria_of_model < validation_accuracy:\n",
        "\n",
        "            torch.save(Model, save_path)\n",
        "            \n",
        "            saving_criteria_of_model = validation_accuracy\n",
        "            \n",
        "            print('--------------------------Saving Model---------------------------')\n",
        "         \n",
        "        \n",
        "    plt.figure(figsize=(20, 4))\n",
        "        \n",
        "    x_axis = (range(n_epochs))\n",
        "        \n",
        "    plt.plot(x_axis, training_loss_array, 'r', validation_loss_array, 'b')\n",
        "        \n",
        "    plt.title('A gragh of training loss vs validation loss')\n",
        "        \n",
        "    plt.legend(['train loss', 'validation loss'])\n",
        "        \n",
        "    plt.xlabel('Number of Epochs')\n",
        "        \n",
        "    plt.ylabel('Loss')\n",
        "        \n",
        "    return Model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot-VEosisY7n",
        "colab_type": "code",
        "outputId": "8ddde784-2666-4a54-9957-f2c625f658dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1346
        }
      },
      "source": [
        "n_epochs = 200\n",
        "model = model_traing_and_validation_loop(Model, n_epochs, 'WideResNet.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 / 200 Training loss: 0.012207207679748535, Validation_loss: 0.0149210205078125, Validation_Accuracy: 0.5265\n",
            "--------------------------Saving Model---------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type WideResNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Residual_Block. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Residual_Unit. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Batch_Norm_Relu_Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2 / 200 Training loss: 0.01138174057006836, Validation_loss: 0.013241832733154296, Validation_Accuracy: 0.5355\n",
            "--------------------------Saving Model---------------------------\n",
            "3 / 200 Training loss: 0.010250816345214844, Validation_loss: 0.008921449661254882, Validation_Accuracy: 0.546\n",
            "--------------------------Saving Model---------------------------\n",
            "4 / 200 Training loss: 0.009599799156188965, Validation_loss: 0.010666799545288087, Validation_Accuracy: 0.5335\n",
            "5 / 200 Training loss: 0.010497159004211425, Validation_loss: 0.011702820777893067, Validation_Accuracy: 0.5365\n",
            "6 / 200 Training loss: 0.009748262405395508, Validation_loss: 0.01236709976196289, Validation_Accuracy: 0.551\n",
            "--------------------------Saving Model---------------------------\n",
            "7 / 200 Training loss: 0.008689190864562988, Validation_loss: 0.01157761287689209, Validation_Accuracy: 0.541\n",
            "8 / 200 Training loss: 0.013470507621765137, Validation_loss: 0.010279352188110352, Validation_Accuracy: 0.554\n",
            "--------------------------Saving Model---------------------------\n",
            "9 / 200 Training loss: 0.011622142791748048, Validation_loss: 0.013254545211791991, Validation_Accuracy: 0.557\n",
            "--------------------------Saving Model---------------------------\n",
            "10 / 200 Training loss: 0.014321034431457519, Validation_loss: 0.008628691673278809, Validation_Accuracy: 0.5585\n",
            "--------------------------Saving Model---------------------------\n",
            "11 / 200 Training loss: 0.01217480182647705, Validation_loss: 0.010827082633972168, Validation_Accuracy: 0.5635\n",
            "--------------------------Saving Model---------------------------\n",
            "12 / 200 Training loss: 0.014618563652038574, Validation_loss: 0.008560722351074218, Validation_Accuracy: 0.5605\n",
            "13 / 200 Training loss: 0.016198352813720705, Validation_loss: 0.008588444709777833, Validation_Accuracy: 0.55\n",
            "14 / 200 Training loss: 0.012928678512573242, Validation_loss: 0.011440253257751465, Validation_Accuracy: 0.5745\n",
            "--------------------------Saving Model---------------------------\n",
            "15 / 200 Training loss: 0.007272866249084473, Validation_loss: 0.01318170738220215, Validation_Accuracy: 0.577\n",
            "--------------------------Saving Model---------------------------\n",
            "16 / 200 Training loss: 0.007613238334655762, Validation_loss: 0.008954001426696776, Validation_Accuracy: 0.573\n",
            "17 / 200 Training loss: 0.013543312072753905, Validation_loss: 0.00687273120880127, Validation_Accuracy: 0.576\n",
            "18 / 200 Training loss: 0.008234297752380371, Validation_loss: 0.008430710792541504, Validation_Accuracy: 0.5775\n",
            "--------------------------Saving Model---------------------------\n",
            "19 / 200 Training loss: 0.012841209411621094, Validation_loss: 0.007965137481689453, Validation_Accuracy: 0.5905\n",
            "--------------------------Saving Model---------------------------\n",
            "20 / 200 Training loss: 0.008144670486450196, Validation_loss: 0.014074839591979981, Validation_Accuracy: 0.591\n",
            "--------------------------Saving Model---------------------------\n",
            "21 / 200 Training loss: 0.012083637237548827, Validation_loss: 0.012410229682922363, Validation_Accuracy: 0.5895\n",
            "22 / 200 Training loss: 0.009863892555236816, Validation_loss: 0.0073254556655883785, Validation_Accuracy: 0.57\n",
            "23 / 200 Training loss: 0.010961577415466309, Validation_loss: 0.006652821063995362, Validation_Accuracy: 0.5855\n",
            "24 / 200 Training loss: 0.009347352981567383, Validation_loss: 0.013212752342224122, Validation_Accuracy: 0.5845\n",
            "25 / 200 Training loss: 0.006598392963409424, Validation_loss: 0.010002349853515625, Validation_Accuracy: 0.5805\n",
            "26 / 200 Training loss: 0.00883304214477539, Validation_loss: 0.015327015876770019, Validation_Accuracy: 0.58\n",
            "27 / 200 Training loss: 0.008011967658996581, Validation_loss: 0.00854295539855957, Validation_Accuracy: 0.595\n",
            "--------------------------Saving Model---------------------------\n",
            "28 / 200 Training loss: 0.009717272758483888, Validation_loss: 0.010347301483154298, Validation_Accuracy: 0.595\n",
            "29 / 200 Training loss: 0.008067384719848632, Validation_loss: 0.0093919038772583, Validation_Accuracy: 0.618\n",
            "--------------------------Saving Model---------------------------\n",
            "30 / 200 Training loss: 0.01081096363067627, Validation_loss: 0.010440293312072755, Validation_Accuracy: 0.5995\n",
            "31 / 200 Training loss: 0.010920080184936523, Validation_loss: 0.01029135799407959, Validation_Accuracy: 0.592\n",
            "32 / 200 Training loss: 0.015450984954833984, Validation_loss: 0.009346839904785156, Validation_Accuracy: 0.6165\n",
            "33 / 200 Training loss: 0.009131735801696777, Validation_loss: 0.006378766059875488, Validation_Accuracy: 0.6085\n",
            "34 / 200 Training loss: 0.010967421531677245, Validation_loss: 0.009340994834899903, Validation_Accuracy: 0.6005\n",
            "35 / 200 Training loss: 0.01344270896911621, Validation_loss: 0.013295150756835938, Validation_Accuracy: 0.618\n",
            "36 / 200 Training loss: 0.006852909088134766, Validation_loss: 0.00699290132522583, Validation_Accuracy: 0.611\n",
            "37 / 200 Training loss: 0.011339136123657226, Validation_loss: 0.007378302574157715, Validation_Accuracy: 0.6395\n",
            "--------------------------Saving Model---------------------------\n",
            "38 / 200 Training loss: 0.008184666633605958, Validation_loss: 0.01001827049255371, Validation_Accuracy: 0.6305\n",
            "39 / 200 Training loss: 0.00809854793548584, Validation_loss: 0.008996227264404296, Validation_Accuracy: 0.64\n",
            "--------------------------Saving Model---------------------------\n",
            "40 / 200 Training loss: 0.0075076684951782225, Validation_loss: 0.00869511890411377, Validation_Accuracy: 0.64\n",
            "41 / 200 Training loss: 0.00926980209350586, Validation_loss: 0.009406661987304688, Validation_Accuracy: 0.6395\n",
            "42 / 200 Training loss: 0.008780284881591797, Validation_loss: 0.009320293426513672, Validation_Accuracy: 0.639\n",
            "43 / 200 Training loss: 0.008238101959228515, Validation_loss: 0.009216713905334472, Validation_Accuracy: 0.647\n",
            "--------------------------Saving Model---------------------------\n",
            "44 / 200 Training loss: 0.008141140937805175, Validation_loss: 0.007896986961364746, Validation_Accuracy: 0.66\n",
            "--------------------------Saving Model---------------------------\n",
            "45 / 200 Training loss: 0.006250686168670654, Validation_loss: 0.01207901954650879, Validation_Accuracy: 0.6355\n",
            "46 / 200 Training loss: 0.012237350463867187, Validation_loss: 0.013040492057800293, Validation_Accuracy: 0.647\n",
            "47 / 200 Training loss: 0.010345312118530273, Validation_loss: 0.00924083137512207, Validation_Accuracy: 0.652\n",
            "48 / 200 Training loss: 0.009117928504943848, Validation_loss: 0.006523374080657959, Validation_Accuracy: 0.655\n",
            "49 / 200 Training loss: 0.012124897003173828, Validation_loss: 0.010035845756530761, Validation_Accuracy: 0.6405\n",
            "50 / 200 Training loss: 0.008510623931884766, Validation_loss: 0.006558226585388184, Validation_Accuracy: 0.645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26QAYygOsyAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_saved_model = torch.load('WideResNet.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H4jjYea3vSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_input = torch.FloatTensor(1,3,224,224)\n",
        "dummy_input = dummy_input.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj_J07qs3iXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.onnx.export(load_saved_model, dummy_input, 'WideResNet.onnx')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}